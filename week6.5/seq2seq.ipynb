{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K40m (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Problem & Dataset\n",
    "\n",
    "* Chemistry is not a mostly loved subject.\n",
    "* There are various chemical compounds. The problem here is to pronounce a common name knowing its formula.  \n",
    "* So, we try to learn transition: molecular_formula->common_name.\n",
    "* If you want, you can replace source and target variables to predict something else (sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "molecules = pd.read_csv('molecules.tsv',sep='\\t')\n",
    "\n",
    "def get_xy(x, y):\n",
    "    global molecules\n",
    "    is_str = lambda s: type(s) is str\n",
    "    molecules = molecules[x.apply(is_str)& y.apply(is_str)]\n",
    "    x = x[x.apply(is_str)& y.apply(is_str)]\n",
    "    y = y[x.apply(is_str)& y.apply(is_str)]\n",
    "    return x.values, y.apply(lambda s: [\"START\"]+list(s)+[\"END\"])\n",
    "\n",
    "source_seqs,target_seqs = get_xy(molecules.molecular_formula, molecules.common_name) #Replace here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_{7}H_{11}NO_{5} : Ethyl 3-ethoxy-2-nitroacrylate\n",
      "C_{20}H_{20}FN_{3}O : N-Butyl-3-(4-fluorophenyl)-1-phenyl-1H-pyrazole-5-carboxamide\n",
      "C_{17}H_{23}NOS : N-Butyl-N-sec-butyl-1-benzothiophene-3-carboxamide\n",
      "C_{21}H_{29}N_{5}O_{3} : 2-{6-[(2S)-2-Butanyl]-2-(2-methyl-2-propanyl)-5,8-dioxo-5,6,7,8-tetrahydro-4H-pyrazolo[1,5-a]pyrrolo[3,4-d]pyrimidin-4-yl}-N-cyclopropylacetamide\n",
      "C_{13}H_{22}BrN_{3}O_{2} : 4-Bromo-5-[(3-hydroxy-2,3-dimethyl-2-butanyl)amino]-2-propyl-3(2H)-pyridazinone\n"
     ]
    }
   ],
   "source": [
    "for source, target in zip(source_seqs[:5],target_seqs[:5]):\n",
    "    print( source,':',\"\".join(target[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_letters = list(set([token for ts in target_seqs for token in ts]))\n",
    "target_letter_to_ix = {ph:i for i,ph in enumerate(target_letters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_letters = list(set([token for word in source_seqs for token in word]))\n",
    "source_letter_to_ix = {l:i for i,l in enumerate(source_letters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f268cddb240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(list(map(len,target_seqs)),bins=25);\n",
    "\n",
    "# Truncate names longer than MAX_LEN characters. This can be changed\n",
    "MAX_LEN = min([150,max(list(map(len,target_seqs)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into matrix of int32. Pad with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def as_matrix(sequences,token_to_i, max_len=None,PAX_ix=-1):\n",
    "    \"\"\"\n",
    "    Converts several sequences of tokens to a matrix, edible a neural network.\n",
    "    Crops at max_len(if given), pads shorter sequences with -1 or PAD_ix.\n",
    "    \"\"\"\n",
    "    max_len = max_len or max(map(len,sequences))\n",
    "    \n",
    "    matrix = np.zeros((len(sequences),max_len),dtype='int32') -1\n",
    "    for i,seq in enumerate(sequences):\n",
    "        \n",
    "        row_ix = [token_to_i.get(_, 0) for _ in seq[:max_len]]\n",
    "        matrix[i,:len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 37 29 22 14  1 37 29 33 33 14 42  2 37 29 13 14 -1 -1 -1 -1 -1 -1 -1\n",
      "  -1 -1 -1 -1]\n",
      " [11 37 29 36 32 14  1 37 29 36 32 14 48 42 37 29  9 14  2 -1 -1 -1 -1 -1\n",
      "  -1 -1 -1 -1]\n",
      " [11 37 29 33 22 14  1 37 29 36  9 14 42  2  5 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "  -1 -1 -1 -1]\n",
      " [11 37 29 36 33 14  1 37 29 36 27 14 42 37 29 13 14  2 37 29  9 14 -1 -1\n",
      "  -1 -1 -1 -1]\n",
      " [11 37 29 33  9 14  1 37 29 36 36 14 50 19 42 37 29  9 14  2 37 29 36 14\n",
      "  -1 -1 -1 -1]\n",
      " [11 37 29 33  6 14  1 37 29 33 13 14 42 37 29  9 14  2 37 29  9 14 -1 -1\n",
      "  -1 -1 -1 -1]\n",
      " [11 37 29 36 22 14  1 37 29 36  9 14 11 21 37 29 36 14 42  2 37 29 13 14\n",
      "  -1 -1 -1 -1]\n",
      " [11 37 29 33 36 14  1 37 29 33 36 14 48 37 29  9 14 42 37 29  9 14  2 37\n",
      "  29 36 14  5]\n",
      " [11 37 29 33 22 14  1 37 29 33 27 14 11 21 42 37 29 36 14  2 -1 -1 -1 -1\n",
      "  -1 -1 -1 -1]\n",
      " [11 37 29 33 33 14  1 37 29 33 27 14 11 21 42 37 29 23 14 -1 -1 -1 -1 -1\n",
      "  -1 -1 -1 -1]]\n"
     ]
    }
   ],
   "source": [
    "print(as_matrix(source_seqs[:10],source_letter_to_ix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.matrix('token sequence','int32')\n",
    "target_target_letters = T.matrix('target target_letters','int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build NN\n",
    "\n",
    "You will be building a model that takes token sequence and predicts next token\n",
    "\n",
    "\n",
    "* Input sequence\n",
    "* One-hot / embedding\n",
    "* Encoder recurrent layer(s)\n",
    "* Decoder recurrent layer(s)\n",
    "* Softmax layer to predict probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import *\n",
    "\n",
    "##ENCODER\n",
    "l_in = InputLayer(shape=(None, None), input_var=input_sequence)\n",
    "l_mask = InputLayer(shape=(None, None), input_var=T.neq(input_sequence, -1)) \n",
    "\n",
    "l_emb = EmbeddingLayer(l_in, len(source_letters), 8)\n",
    "l_rnn = GRULayer(l_emb, 100, only_return_final=True, mask_input=l_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##DECODER\n",
    "dec_in = InputLayer(shape=(None, None), input_var=target_target_letters)\n",
    "dec_mask = InputLayer(shape=(None, None), input_var=T.neq(target_target_letters,-1))\n",
    "\n",
    "dec_emb = EmbeddingLayer(dec_in, len(target_letters), 8)\n",
    "dec_rnn = GRULayer(dec_emb, 100, hid_init=l_rnn, mask_input=dec_mask)# WARNING! if it's lstm use cell_init, not hid_init\n",
    "\n",
    "\n",
    "#flatten batch and time to be compatible with feedforward layers (will un-flatten later)\n",
    "dec_rnn_flat = reshape(dec_rnn, (-1, dec_rnn.output_shape[-1]))\n",
    "\n",
    "l_out = lasagne.layers.DenseLayer(dec_rnn_flat, len(target_letters), nonlinearity=lasagne.nonlinearities.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model weights\n",
    "weights = get_all_params(l_out,trainable=True)\n",
    "#print weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network_output = get_output(l_out)\n",
    "network_output = network_output.reshape([target_target_letters.shape[0],target_target_letters.shape[1],-1])\n",
    "#If you use dropout do not forget to create deterministic version for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_flat = network_output[:,:-1,:].reshape([-1,len(target_letters)])\n",
    "targets = target_target_letters[:,1:].ravel()\n",
    "\n",
    "#do not count loss for '-1' tokens\n",
    "mask = T.nonzero(T.neq(targets,-1))\n",
    "\n",
    "loss = lasagne.objectives.categorical_crossentropy(predictions_flat[mask], targets[mask]).mean()\n",
    "\n",
    "updates = lasagne.updates.adam(loss, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training\n",
    "train = theano.function([input_sequence, target_target_letters], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "#computing loss without training\n",
    "compute_cost = theano.function([input_sequence, target_target_letters], loss, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation\n",
    "\n",
    "We now need to implement a function that generates output sequence given input.\n",
    "\n",
    "Such function must work thusly:\n",
    "```\n",
    "Init:\n",
    "x = input\n",
    "y = [\"START\"]\n",
    "\n",
    "While not_too_long:\n",
    "  p(y_next|x,y) = probabilities of next letter for y\n",
    "  \n",
    "  y_next ~ p(y_next|x,y)\n",
    "  \n",
    "  y.append(y_next)\n",
    "  \n",
    "  if y_next == \"END\":\n",
    "      break\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compile the function that computes probabilities for next token given previous text.\n",
    "\n",
    "network_output = network_output.reshape((target_target_letters.shape[0],\n",
    "                                         target_target_letters.shape[1], len(target_letters)))\n",
    "\n",
    "last_word_probas = network_output[:,-1,:]\n",
    "\n",
    "probs = theano.function([input_sequence, target_target_letters], last_word_probas, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_output(input,\n",
    "                    output_prefix = (\"START\",),\n",
    "                    END_token=\"END\",\n",
    "                    t=1,\n",
    "                    sample=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Implement a function that generates output sequence given input.\n",
    "    \n",
    "    We recommend (but not require) you to use the pseudo-code above and inline instructions.\n",
    "    \"\"\"\n",
    "    \n",
    "    output = list(output_prefix)\n",
    "    \n",
    "    while True:\n",
    "        next_y_probs = probs(as_matrix([input], source_letter_to_ix),\n",
    "                             as_matrix([output], target_letter_to_ix)).ravel()\n",
    "        next_y_probs = next_y_probs ** t / np.sum(next_y_probs ** t)\n",
    "\n",
    "        if sample:\n",
    "            ix = np.random.choice(np.arange(len(target_letters)), p=next_y_probs)\n",
    "            next_y = target_letters[ix]\n",
    "        else:\n",
    "            next_y = target_letters[next_y_probs.argmax()]\n",
    "        \n",
    "        assert type(next_y) is str, \"please return token(string/character), not it's index\"\n",
    "        \n",
    "        output.append(next_y)\n",
    "\n",
    "        if next_y==END_token:\n",
    "            break\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_seqs = np.array(source_seqs)\n",
    "target_seqs = np.array(target_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_batch(source_seqs,target_seqs, batch_size):\n",
    "    \"\"\"samples a random batch of source and target sequences, batch_size elements\"\"\"\n",
    "    batch_ix = np.random.randint(0,len(source_seqs),size=batch_size)\n",
    "    source_seqs_batch=as_matrix(source_seqs[batch_ix],source_letter_to_ix) \n",
    "    target_seqs_batch=as_matrix(target_seqs[batch_ix],target_letter_to_ix)\n",
    "    \n",
    "    return source_seqs_batch,target_seqs_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 average loss = 0.5788296856284142\n",
      "C_{24}H_{22}F_{5}N_{3}O_{4} : 2-{[4-(4-Methoxyphenyl)-3-thienyl]sulfanyl}methylene]-2-(2-chlorophenyl)-4H-chromene-3-carboxylic acid\n",
      "C_{13}H_{20}ClN_{3}O_{2} : N-(3-Chlorophenyl)-3-[1-[(E)-(methylamino)methyl]-2-pyrrolidinone\n",
      "C_{14}H_{20}N_{2}O : 1-[3-Fluoro-1-(2-fluorophenyl)aniline]-4-naphthaleneseridione\n",
      "C_{12}H_{12}Cl_{3}NO : 1-Cyclopropyl-1-oxo-2-(2-propoxyethoxy)propanoyl}benzonate>l)]sulfonamide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/500 [00:00<00:41, 12.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_{15}H_{12}Cl_{2}FNS : 7-[({4-[(3-Chlorobenzyl)oxy]-N-(phenoxymethyl)cyclopropanecarboxamide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:51<00:00,  9.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 average loss = 0.5743788164258004\n",
      "C_{21}H_{26}N_{2}O_{2} : 4-Amino-1-(1H-1,2-benzodioxino-1,4-dihydropyrido[2,3-a]isoquinolin-2-yl)-1-[4-iodo-3-hydramido-4(5H)-pyridazinone\n",
      "C_{8}H_{12}ClN : 2-(Ethylsulfamoyl)phenium\n",
      "C_{19}H_{13}N_{3}O : 4-[(3,5-Dimethylphenyl)sulfamoate\n",
      "C_{20}H_{21}ClN_{2}O_{3}S : [(2-{[(2-Bromophenyl)sulfonyl]-1-methoxy-6,7-diphenyl-2-thiomorpholinecarboxamide hydrac diamide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:00<01:29,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_{16}H_{24}N_{4}O : N-(1,1-Diethylmethyl)-N-(3,4-dichlorophenyl)-5-piperidinecarboxamide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:53<00:00,  9.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 average loss = 0.5765019021034241\n",
      "C_{12}H_{16}FN_{5} : 5-(3,3-Dihydro-1H-1,2,4-triazol-3-yl)-5-methoxybenzenesulfonamide\n",
      "C_{16}H_{25}NOS_{2} : N-[3-(2-Methyl-2-propanyl)-4,6'-bis(6-methyl-2,4-dimethyl-1H-pyrrol-1-yl)benzoic acid\n",
      "C_{15}H_{30}N_{2}O_{3} : N,N-Dimethyl-4-[4-(tetrahydro-2-furanylmethyl)-2-methoxybenzyl]imino}benzoate\n",
      "C_{16}H_{26}N_{4}O_{3}S : N-[2-(1,3,5,5,6,8,6,7a-D,8-tetrahydro-2H-1,4-benzodioxin-6-yl)ethyl]-9-phenylbenzene\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:00<00:57,  8.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_{26}H_{25}F_{2}N_{3}O_{3}S : 2-(3-Cyanobenzoyl)-6-{[3-(2-thienylmethyl)-3-morpholinyl]amino}-2,6-dichlorobenzoic acid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:52<00:00,  9.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 average loss = 0.5724894424676895\n",
      "C_{18}H_{25}N_{3}O_{5} : N-[1-(2,4-Dimethylphenyl)-3-(3-methoxyphenyl)-2,3-dihydro-2-propanone\n",
      "C_{11}H_{17}NO_{4}S_{2} : 5-[Isobutyloxy)methylene]-2-thiophene-7-carboxylate\n",
      "C_{10}H_{14}N_{4}O : N-[3-(2-Methyl-2-propen-1-yl)propyl]-2-furamide\n",
      "C_{23}H_{26}ClNO_{6} : 2-(Cyclopentyl-3-{[(3-cyanophenyl)sulfonyl]-4carbaminocyclohexanecarbonitrile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/500 [00:00<00:43, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_{20}H_{21}N_{5}O_{2} : (2,2-Dimethyl-beta-alanyl-1H-pyrazol-4-yl)(soc-ethyl)carbamoyl]-4-(methylsul)-1-benzofuran-1-yl diencyl-3,3,5-trimethylbicyclo[2.3.1]nona--1,1-d]quinoxalin-2-amine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:54<00:00,  9.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 average loss = 0.5787802811264992\n",
      "C_{11}H_{21}NO_{3} : 2-Amino-N-(2,3,4-trifluoro-4H-1,3,4-triazol-3-oncy)methyl}benzene\n",
      "C_{19}H_{19}N_{3}O_{2}S : 2-{[2-(Aminomethyl)-3-nitrobenzoyl]amino}benzoic acid\n",
      "C_{10}H_{13}N_{3}O : [(4-Phenoxyphenyl)amino]methyl}benzamide\n",
      "C_{10}H_{17}N_{5}O : N-(1-Methoxycyclohexyl)-1-(2-methyl-2-pentanyl)-1H-1,2,4-triazol-5-amine\n",
      "C_{19}H_{18}N_{6}OS : 2-(4-Amanophenoxy)-3-(3,4-dimethylphenyl)-3-oxo-4-propyl-5,7-pyrimidinedicarboxamide\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "#total N iterations\n",
    "n_epochs=100\n",
    "\n",
    "# how many minibatches are there in the epoch \n",
    "batches_per_epoch = 500\n",
    "\n",
    "#how many training sequences are processed in a single function call\n",
    "batch_size=10\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "\n",
    "    avg_cost = 0;\n",
    "    \n",
    "    for _ in tqdm(range(batches_per_epoch)):\n",
    "        \n",
    "        x,y = sample_batch(source_seqs,target_seqs,batch_size)\n",
    "        avg_cost += train(x, y).mean()\n",
    "    if epoch % 5 == 0:\n",
    "        clear_output(True)\n",
    "        \n",
    "    print(\"Epoch {} average loss = {}\".format(epoch, avg_cost / batches_per_epoch))\n",
    "    for i in range(5):\n",
    "        ind = np.random.randint(len(source_seqs))\n",
    "        print (source_seqs[ind],':', ''.join(generate_output(source_seqs[ind],sample=True)[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_{19}H_{18}N_{6}OS : (1R,3R)-1-(2-Amino-1-phenyl-6,6-dihydro-5H-1,4-benzoxazin-4-yl)-2-oxoethyl (1R,3R)-1-(1-phenylethyl)-1,3-benzoxazole-3-carboxamide\n"
     ]
    }
   ],
   "source": [
    "print (source_seqs[ind],':', ''.join(generate_output(\" C_{4}H_{1}\", t=2)[1:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework part 2 - chemistry (6 pt total)\n",
    "\n",
    "* [4pts] Complete notebook and make sure target sequence is being generated.\n",
    "* [2pts] Modify train cycle to output sequences with different sampling strategies (varying t in range $[0, + \\infty)$ and try to find out which sampling strategy is the best for current task)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [bonus] [2pts]  Latex display\n",
    "Swap target and source and learn name->formula, then try to reach quality when almos any generated sequence is a valid Latex formula and implement its prinitng using IPython magic in jupyter. It would be good if you create a demo and pass there some chemical (or not?) names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$2+2$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IPython\n",
    "z = IPython.display.Latex(data='$2+2$')\n",
    "IPython.display.display(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And now,\n",
    "* try lstm/gru\n",
    "* try several layers\n",
    "* try mtg cards\n",
    "* try your own dataset of any kind"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
